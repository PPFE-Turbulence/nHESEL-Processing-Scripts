{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a4595ef-5daf-4f77-b60f-d3e831ef4c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of RAW folders: 0\n",
      "Total file size: 1e-12 TB\n",
      "\n",
      "Amount of processed folders: 0\n",
      "Total file size: 1e-09 GB\n"
     ]
    }
   ],
   "source": [
    "### FILE SIZE CHECKS ###\n",
    "import os\n",
    "def getFolderSize(folder):\n",
    "    total_size = os.path.getsize(folder)\n",
    "    for item in os.listdir(folder):\n",
    "        itempath = os.path.join(folder, item)\n",
    "        if os.path.isfile(itempath):\n",
    "            total_size += os.path.getsize(itempath)\n",
    "        elif os.path.isdir(itempath):\n",
    "            total_size += getFolderSize(itempath)\n",
    "    return total_size\n",
    "\n",
    "dataAmountRAW = len(next(os.walk('HESEL_data'))[1])\n",
    "dataAmountProcessed = len(next(os.walk('HESEL_processed'))[1])\n",
    "dataSizeRAW = getFolderSize(\"HESEL_data\")\n",
    "dataSizeProcessed = getFolderSize(\"HESEL_processed\")\n",
    "\n",
    "print(f\"Amount of RAW folders: {dataAmountRAW}\")\n",
    "print(f\"Total file size: {dataSizeRAW/1e12} TB\")\n",
    "print()\n",
    "print(f\"Amount of processed folders: {dataAmountProcessed}\")\n",
    "print(f\"Total file size: {dataSizeProcessed/1e9} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa231197-01c7-4976-90df-16af4323b721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Checking RAW data =====\n",
      "\n",
      "===== No missing RAW data was found =====\n",
      "\n",
      "\n",
      "===== Checking processed data =====\n",
      "\n",
      "===== No missing processed data was found =====\n"
     ]
    }
   ],
   "source": [
    "### FOLDER STATE CHECKS ###\n",
    "### Libraries imports\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "### Locals imports\n",
    "# Import paths file\n",
    "pathPath = \"os.environ['HOME']\"\n",
    "sys.path.append(pathPath)\n",
    "import paths\n",
    "\n",
    "# Import job submission script\n",
    "sys.path.append(paths.scriptPath)\n",
    "\n",
    "# Import scripts\n",
    "from sweeps import nameGenerator\n",
    "\n",
    "# Create the lists for data for the corresponding datasets\n",
    "listCombies, nameParamList, nameDataList, listProcessed = [], [], [], []\n",
    "\n",
    "\n",
    "# Add the data - these are the folders to check\n",
    "#listCombies, nameParamList, nameDataList, listProcessed = nameGenerator({\"INNERTEMP\" : [670, 850, 20], \"INNERDENSITY\" : [3.0, 4.0, 0.1], \"NOUT\" : 1000}, customSuffix = f\"GridSweep\", roundParameters = {\"INNERDENSITY\" : 2})\n",
    "##listCombies, nameParamList, nameDataList, listProcessed = nameGenerator({\"INNERTEMP\" : [670, 850, 20], \"INNERDENSITY\" : [4.1, 5.0, 0.1], \"NOUT\" : 1000}, customSuffix = f\"GridSweep\", roundParameters = {\"INNERDENSITY\" : 2})\n",
    "\n",
    "# for i in range(5):#range(3):\n",
    "#     listCombiesTEMP, nameParamListTEMP, nameDataListTEMP, listProcessedTEMP = nameGenerator({\"INNERTEMP\" : [100, 2000, 50], \"NOUT\" : [1000]}, customSuffix = f\"P_loss_Curve{i}\")\n",
    "#     listCombies.append(listCombiesTEMP)\n",
    "#     nameParamList.append(nameParamListTEMP)\n",
    "#     nameDataList.append(nameDataListTEMP)\n",
    "#     listProcessed.append(listProcessedTEMP)\n",
    "\n",
    "for i in range(2):\n",
    "    listCombiesTEMP, nameParamListTEMP, nameDataListTEMP, listProcessedTEMP = nameGenerator({\"INNERTEMP\" : [100, 1000, 50], \"NOUT\" : 1000}, customSuffix = f\"Curve_TemplateCheck_{i}\")\n",
    "    listCombies.append(listCombiesTEMP)\n",
    "    nameParamList.append(nameParamListTEMP)\n",
    "    nameDataList.append(nameDataListTEMP)\n",
    "    listProcessed.append(listProcessedTEMP)\n",
    "\n",
    "# Convert to np arrays\n",
    "listCombies = np.array(listCombies)\n",
    "nameParamList = np.array(nameParamList)\n",
    "nameDataList = np.array(nameDataList)\n",
    "listProcessed = np.array(listProcessed)\n",
    "\n",
    "# Now flatten them\n",
    "listCombies = listCombies.flatten()\n",
    "nameParamList = nameParamList.flatten()\n",
    "nameDataList = nameDataList.flatten()\n",
    "listProcessed = listProcessed.flatten()\n",
    "\n",
    "# Now check for the first dump file in each folder\n",
    "allGood = True\n",
    "badList = []\n",
    "print(\"===== Checking RAW data =====\\n\")\n",
    "for i in range(len(nameDataList)):\n",
    "    fPath = f\"{paths.dataPath}/{nameDataList[i]}/BOUT.dmp.0.nc\"\n",
    "    if os.path.isfile(fPath) == False:\n",
    "        allGood = False\n",
    "        print(f\"Missing data in: {nameDataList[i]}\")\n",
    "        bad = listCombies[i]\n",
    "        for key in bad.keys():\n",
    "            if isinstance(bad[key], np.floating):\n",
    "                bad[key] = float(bad[key])\n",
    "            if isinstance(bad[key], np.integer):\n",
    "                bad[key] = int(bad[key])\n",
    "        badList.append(bad)\n",
    "\n",
    "if allGood == True:\n",
    "    print(\"===== No missing RAW data was found =====\\n\\n\")\n",
    "else:\n",
    "    print(\"\\n===== End of list =====\\n\\n\")\n",
    "    print(f\"Missing data parameter combinations: {badList}\\n\\n\")\n",
    "\n",
    "allGood = True\n",
    "print(\"===== Checking processed data =====\\n\")\n",
    "for i in range(len(nameDataList)):\n",
    "    fPath = f\"{paths.processedPath}/{nameDataList[i]}/Gamma_perp_averaged_z.npy\"\n",
    "    if os.path.isfile(fPath) == False:\n",
    "        allGood = False\n",
    "        print(f\"Missing data in: {nameDataList[i]}\")\n",
    "\n",
    "if allGood == True:\n",
    "    print(\"===== No missing processed data was found =====\")\n",
    "else:\n",
    "    print(\"\\n===== End of list=====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43684f48-c080-4def-8b60-48b78d071d39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
